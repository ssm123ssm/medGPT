{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T11:23:19.125153Z",
     "start_time": "2023-07-30T11:23:19.114289Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from docGPT_core import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T11:23:19.489554Z",
     "start_time": "2023-07-30T11:23:19.128108Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set_tokens(OPENAI_TOKEN='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',HF_TOKEN=\"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\")\n",
    "hf_embeddings = Embedding(model_name='sentence-transformers/all-MiniLM-L6-v2', model_type = 'hf')\n",
    "openai_embeddings = Embedding(model_type='openai')\n",
    "llm = Llm(model_type='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T11:23:28.178960Z",
     "start_time": "2023-07-30T11:23:19.490614Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vs_rnd_2000 = load_vectorstore(store_name='store/KnC_OpenAI_embedded_2500.pkl')\n",
    "#vs_rnd_2000 = VectorStore(embedding_model=openai_embeddings,chunk_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T11:23:28.188677Z",
     "start_time": "2023-07-30T11:23:28.183403Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T11:23:28.250087Z",
     "start_time": "2023-07-30T11:23:28.191880Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Building the embedding matrix\n",
    "index = vs_rnd_2000.store.index\n",
    "num_items = len(vs_rnd_2000.store.index_to_docstore_id)\n",
    "embedding_dim = 1536\n",
    "vectors = []\n",
    "for i in range(num_items):\n",
    "    vectors.append(index.reconstruct(i))\n",
    "embedding_matrix = np.array(vectors)\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T11:23:28.250501Z",
     "start_time": "2023-07-30T11:23:28.209530Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_index = (vs_rnd_2000.store.docstore.__dict__['_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T11:23:28.388399Z",
     "start_time": "2023-07-30T11:23:28.248387Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Deciding the number of clusters, based on a maximum token limit\n",
    "import statistics\n",
    "target = 2000\n",
    "chunk_tokens = []\n",
    "\n",
    "for key, value in doc_index.items():\n",
    "    chunk_tokens.append(llm.model.get_num_tokens(value.page_content))\n",
    "\n",
    "mean_chunk_size = statistics.mean(chunk_tokens)\n",
    "\n",
    "if target//mean_chunk_size <= len(chunk_tokens):\n",
    "    num_clusters = (target//mean_chunk_size).__int__()\n",
    "else:\n",
    "    num_clusters = len(chunk_tokens).__int__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T11:23:28.396730Z",
     "start_time": "2023-07-30T11:23:28.389993Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f\"Can afford {num_clusters} clusters , with mean chunk size of {mean_chunk_size} tokens, out of {len(chunk_tokens)} total chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T11:23:28.462906Z",
     "start_time": "2023-07-30T11:23:28.403099Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perform K-means clustering\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42).fit(embedding_matrix)\n",
    "closest_indices = []\n",
    "\n",
    "#based on L2 norm\n",
    "for i in range(num_clusters):\n",
    "    distances = np.linalg.norm(vectors - kmeans.cluster_centers_[i], axis=1)\n",
    "    closest_index = np.argmin(distances)\n",
    "    closest_indices.append(closest_index)\n",
    "\n",
    "selected_indices = sorted(closest_indices)\n",
    "doc_ids = list(map(vs_rnd_2000.store.index_to_docstore_id.get, selected_indices))\n",
    "contents = list(map(vs_rnd_2000.store.docstore.__dict__['_dict'].get, doc_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T11:23:28.463505Z",
     "start_time": "2023-07-30T11:23:28.451176Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "keyword_prompt = \"\"\"\n",
    "You will be given a single passage of a document. This section will be enclosed in triple backticks (```)\n",
    "Your goal is to identify what the passage tries to describe and give five comma separated un-numbered keywords from the passage.\n",
    "\n",
    "```{text}```\n",
    "keywords:\n",
    "\"\"\"\n",
    "\n",
    "map_prompt = \"\"\"\n",
    "You will be given a single passage of a document. This section will be enclosed in triple backticks (```)\n",
    "Your goal is to identify what the passage tries to describe and give the general idea tha passage is discussing, as a summary. Do not focus on specific details and try to understand the general context. Start with This section is mainly obout,\n",
    "```{text}```\n",
    "GENERAL IDEA:\n",
    "\"\"\"\n",
    "map_prompt_template = PromptTemplate(template=map_prompt, input_variables=[\"text\"])\n",
    "keyword_prompt_template = PromptTemplate(template=keyword_prompt, input_variables=[\"text\"])\n",
    "\n",
    "map_chain = load_summarize_chain(llm=llm.model,\n",
    "                                 chain_type=\"stuff\",\n",
    "                                 prompt=map_prompt_template)\n",
    "keyword_chain = load_summarize_chain(llm=llm.model,\n",
    "                                 chain_type=\"stuff\",\n",
    "                                 prompt=keyword_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T11:23:47.927016Z",
     "start_time": "2023-07-30T11:23:28.451551Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Keywords\n",
    "res_2_key = [keyword_chain({\"input_documents\": [i]})['output_text'] for i in contents]\n",
    "\n",
    "#Summary mappings\n",
    "res_2 = [map_chain({\"input_documents\": [i]})['output_text'] for i in contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T11:23:47.936312Z",
     "start_time": "2023-07-30T11:23:47.930490Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mapping keywords to chunks\n",
    "labels = kmeans.labels_\n",
    "string_list = res_2_key\n",
    "label_to_string = dict(zip(range(len(string_list)), string_list))\n",
    "mapped_strings = [label_to_string[label] for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T11:23:49.598726Z",
     "start_time": "2023-07-30T11:23:47.943298Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Wordcloud from keywords\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the text to generate the word cloud from\n",
    "text = \", \".join(mapped_strings)\n",
    "\n",
    "# Create the word cloud object\n",
    "wordcloud = WordCloud(width=2500, height=1200, background_color='white', collocations=False).generate(text)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wordcloud from keywords\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the text to generate the word cloud from\n",
    "text = \", \".join(res_2_key)\n",
    "\n",
    "# Create the word cloud object\n",
    "wordcloud = WordCloud(width=2500, height=1200, background_color='white', collocations=False).generate(text)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T11:23:49.753859Z",
     "start_time": "2023-07-30T11:23:49.599747Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Dimesion reduction for visualization\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity= (len(chunk_tokens) - 1) if len(chunk_tokens) < 30 else 30)\n",
    "embedding_tsne = tsne.fit_transform(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T11:23:49.827149Z",
     "start_time": "2023-07-30T11:23:49.771171Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "labels = pd.Categorical(mapped_strings)\n",
    "df = pd.DataFrame({'x': embedding_tsne[:, 0], 'y': embedding_tsne[:, 1],  'cluster': labels})\n",
    "\n",
    "fig = px.scatter(df, x='x', y='y', color='cluster')\n",
    "fig.update_layout(title='t-SNE visualization of embedding matrix', xaxis_title='x', yaxis_title='y')\n",
    "fig.update_traces(showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T11:23:49.832264Z",
     "start_time": "2023-07-30T11:23:49.828490Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary_map = ''.join(['\\n\\nSummary: ' + s for s in res_2])\n",
    "summary_doc = Document(page_content = summary_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T11:23:49.866765Z",
     "start_time": "2023-07-30T11:23:49.833375Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary_prompt = \"\"\"\n",
    "    You will be given a set of summaries of randomly selected passages from a document.\n",
    "    Your goal is to write a paragraph on what the document is likely to be about.\n",
    "\n",
    "    ```{text}```\n",
    "\n",
    "    The document is:\n",
    "    \"\"\"\n",
    "\n",
    "insights_prompt = \"\"\"\n",
    "    You will be given a set of summaries of passages from a document.\n",
    "    Your goal is to generate an overall general summary of the document using the summaries provided below within triple backticks.\n",
    "\n",
    "    ```{text}```\n",
    "\n",
    "    OVERALL CONTENT: Provide a list of bullet points.\n",
    "    \"\"\"\n",
    "\n",
    "questions_prompt = \"\"\"\n",
    "    You will be given a set of summaries of passages from a document.\n",
    "    Your goal is to generate an overall general comprehensive summary of the document using the summaries provided below within triple backticks and ask them as questions.\n",
    "\n",
    "    ```{text}```\n",
    "\n",
    "    QUESTIONS: Provide a list of questions.\n",
    "    \"\"\"\n",
    "\n",
    "summary_prompt_template = PromptTemplate(template=summary_prompt, input_variables=[\"text\"])\n",
    "insights_prompt_template = PromptTemplate(template=insights_prompt, input_variables=[\"text\"])\n",
    "questions_prompt_template = PromptTemplate(template=questions_prompt, input_variables=[\"text\"])\n",
    "\n",
    "summary_chain = load_summarize_chain(llm=llm.model,\n",
    "                                 chain_type=\"stuff\",\n",
    "                                 prompt=summary_prompt_template)\n",
    "insights_chain = load_summarize_chain(llm=llm.model,\n",
    "                                     chain_type=\"stuff\",\n",
    "                                     prompt=insights_prompt_template)\n",
    "questions_chain = load_summarize_chain(llm=llm.model,\n",
    "                                      chain_type=\"stuff\",\n",
    "                                      prompt=questions_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T11:24:04.192830Z",
     "start_time": "2023-07-30T11:23:49.842319Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_summary = summary_chain({\"input_documents\": [summary_doc]})\n",
    "#insights = insights_chain({\"input_documents\": [summary_doc]})\n",
    "#questions = questions_chain({\"input_documents\": [summary_doc]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T11:24:04.207072Z",
     "start_time": "2023-07-30T11:24:04.194556Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(final_summary['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T11:24:04.248859Z",
     "start_time": "2023-07-30T11:24:04.208972Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(insights['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T11:24:04.249407Z",
     "start_time": "2023-07-30T11:24:04.216775Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(questions['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T11:24:04.249614Z",
     "start_time": "2023-07-30T11:24:04.224077Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#chain = Chain(retriever=Retriever(vectorstore=custom.load_vectorstore('store/KnC_OpenAI_embedded_2500.pkl'), k=4), llm=llm, persona=Persona(personality_type='explainer'))\n",
    "#chain = Chain(retriever=Retriever(vectorstore=custom.load_vectorstore('store/KnC_OpenAI_embedded_5000.pkl'), k=1), llm=llm, persona=Persona(personality_type='explainer'))\n",
    "\n",
    "#chain = Chain(retriever=Retriever(vectorstore=custom.load_vectorstore('store/BNF_OpenAI_embedded_2000.pkl'), k=4), llm=llm, persona=Persona(personality_type='explainer'))\n",
    "\n",
    "chain = Chain(retriever=Retriever(vs_rnd_2000, k = 4), llm=llm, persona=Persona(personality_type='explainer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = chain.qa(inputs={\"query\": \"A 65-year-old man with hypertension comes to the physician for a routine health maintenance examination. Current medications include atenolol, lisinopril, and atorvastatin. His pulse is 86/min, respirations are 18/min, and blood pressure is 145/95 mm Hg. Cardiac examination reveals end diastolic murmur. Which of the following is the most likely cause of this physical examination?Answer: (A) Decreased compliance of the left ventricle (B) Myxomatous degeneration of the mitral valve (C) Inflammation of the pericardium (D) Dilation of the aortic root (E) Thickening of the mitral valve leaflets\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = VectorStore(embedding_model=openai_embeddings)\n",
    "chain = Chain(retriever=Retriever(vs, k=4), llm=llm, persona=Persona(personality_type='explainer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RVS\n",
    "import importlib\n",
    "importlib.reload(RVS)\n",
    "sm = RVS.summarize(vectorstore=vs, llm=llm, max_tokens=500, summary=False, keypoints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sm['keypoints'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
